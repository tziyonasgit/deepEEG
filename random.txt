



sintx --ntasks=1 --account=l40sfree --partition=l40s
sintx --ntasks=1 --account=compsci --partition=ada
conda activate EEGPT_env

module load python/miniconda3-py3.9
source activate /home/chntzi001/.conda/envs/EEGPT_env

pip install pyhealth

/scratch/chntzi001/TUAB/processed

To install PyHealth version 1.1.4:
git clone --branch v1.1.4 https://github.com/sunlabuiuc/PyHealth.git
cd PyHealth
pip install .


du -sh * | sort -hr
check if running an interactive job:
squeue -u $USER

conda activate EEGPT_env
wandb sweep config.yaml

accessing tensorboard log:
conda activate EEGPT_env
tensorboard --logdir=/home/chntzi001/deepEEG/EEGPT/downstream/log/multiclass/29-07 --port=6006
tensorboard --logdir=. --port=6006
ssh -L 6006:localhost:6006 chntzi001@srvrochpc001

in local terminal: xs


/scratch/chntzi001/khula/24M/1_191_32976770_12_20240313_013012002_processed.set

  1_191_35197624_3_20220726_020636004_processed.set                           



test_sub_src: /scratch/chntzi001/khula/24M/1_191_38017803_24_20240129_110020002_processed.set, match.group(1): 24
multiprocessing.pool.RemoteTraceback:
"""
Traceback (most recent call last):
  File "/home/chntzi001/.conda/envs/EEGPT_env/lib/python3.9/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/home/chntzi001/.conda/envs/EEGPT_env/lib/python3.9/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/home/chntzi001/deepEEG/make_khula.py", line 69, in split_and_dump
    for file in os.listdir(fetch_file):
NotADirectoryError: [Errno 20] Not a directory: '/scratch/chntzi001/khula/12M/1_191_37553535_12_20230821_015704002_processed.set'
"""
/                                                 scratch/chntzi001/khula/12M
The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/chntzi001/deepEEG/make_khula.py", line 317, in <module>
    result = pool.map(split_and_dump, parameters)
  File "/home/chntzi001/.conda/envs/EEGPT_env/lib/python3.9/multiprocessing/pool.py", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File "/home/chntzi001/.conda/envs/EEGPT_env/lib/python3.9/multiprocessing/pool.py", line 771, in get
    raise self._value
NotADirectoryError: [Errno 20] Not a directory: '/scratch/chntzi001/khula/12M/1_191_37553535_12_20230821_015704002_processed.set'

1_191_24503296_3_20220813_104317002_processed.set

FileNotFoundError: [Errno 2] No such file or directory: '/scratch/chntzi001/khula/train/1_191_19175800_6_20230216_092411002_processed_0.pkl'


⚠️ Skipping non-epoched file: /scratch/chntzi001/khula/12M/1_191_43759364_12_T_20230719_105955002_processed.set
⚠️ Skipping non-epoched file: /scratch/chntzi001/khula/12M/1_191_58011621_12_20230823_013452002_processed.set
❌ Cannot read file (corrupt?): /scratch/chntzi001/khula/24M/1_191_47621245_24_20240201_125136002_processed.set
  → Error: could not read bytes
❌ Cannot read file (corrupt?): /scratch/chntzi001/khula/3M/1_191_47621245_3_20220816_113421002_processed.set
  → Error: could not read bytes
❌ Cannot read file (corrupt?): /scratch/chntzi001/khula/6M/1_191_23150844_6_20230131_020106002_processed.set
  → Error: could not read bytes
❌ Cannot read file (corrupt?): /scratch/chntzi001/khula/6M/1_191_23603310_6_20230405_113844002_processed.set
  → Error: could not read bytes
❌ Cannot read file (corrupt?): /scratch/chntzi001/khula/6M/1_191_28039912_6_20230111_011331002_processed.set
  → Error: could not read bytes
❌ Cannot read file (corrupt?): /scratch/chntzi001/khula/6M/1_191_28097536_6_S_20221206_020230002_processed.set
  → Error: could not read bytes
❌ Cannot read file (corrupt?): /scratch/chntzi001/khula/6M/1_191_37298891_6_20230308_092006002_processed.set
  → Error: could not read bytes
⚠️ Skipping non-epoched file: /scratch/chntzi001/khula/6M/1_191_59659447_6_20230330_013531002_processed.set
❌ Cannot read file (corrupt?): /scratch/chntzi001/khula/6M/1_191_70439269_6_20230119_112718002_processed.set
  → Error: could not read bytes
                                

lr!!!! is: 4e-05
lr0.000040@!!!!!!!
Namespace(batch_size=128, epochs=30, update_freq=1, save_ckpt_freq=50, log_dir='/home/chntzi001/deepEEG/EEGPT/downstream/log/multiclass/28-07/lr0.000040_bs128_e30', output_dir='/scratch/chntzi001/khula/checkpoints/finetune_khula_eegpt', sweep=False, robust_test=None, model='EEGPT', qkv_bias=False, rel_pos_bias=False, abs_pos_emb=True, layer_scale_init_value=0.1, input_size=200, drop=0.0, attn_drop_rate=0.0, drop_path=0.1, disable_eval_during_finetuning=False, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=5.0, momentum=0.9, weight_decay=0.05, weight_decay_end=None, lr=4e-05, layer_decay=0.65, warmup_lr=1e-06, min_lr=1e-06, warmup_epochs=5, warmup_steps=-1, smoothing=0.1, reprob=0.25, remode='pixel', recount=1, resplit=False, finetune='/home/chntzi001/deepEEG/EEGPT/downstream/Checkpoints/eegpt_mcae_58chs_4s_large4E.ckpt', model_key='model|module|state_dict', model_prefix='', model_filter_name='gzp', init_scale=0.001, use_mean_pooling=True, disable_weight_decay_on_rel_pos_bias=False, nb_classes=4, device='cuda', seed=0, resume='', auto_resume=False, save_ckpt=True, start_epoch=0, eval=False, dist_eval=True, num_workers=0, pin_mem=True, distributed=False, world_size=1, local_rank=-1, dist_on_itp=False, dist_url='env://', enable_deepspeed=False, dataset='KHULA')

model:  EEGPTClassifier(
  (chan_conv): Sequential(
    (0): Conv2dWithConstraint(54, 54, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): GELU(approximate='none')
    (3): Conv2d(54, 54, kernel_size=(1, 55), stride=(1, 1), padding=same, groups=54)
    (4): BatchNorm2d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): Dropout(p=0.8, inplace=False)
  )
  (target_encoder): EEGTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(1, 512, kernel_size=(1, 64), stride=(1, 64))
    )
    (chan_embed): Embedding(58, 512)
    (blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  )
  (reconstructor): EEGTransformerReconstructor(
    (reconstructor_embed): Linear(in_features=512, out_features=512, bias=True)
    (time_embed): RotaryEmbedding()
    (chan_embed): Embedding(58, 512)
    (reconstructor_blocks): ModuleList(
      (0-7): 8 x Block(
        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=512, out_features=1536, bias=True)
          (proj): Linear(in_features=512, out_features=512, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=512, out_features=2048, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=2048, out_features=512, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (reconstructor_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    (reconstructor_proj): Linear(in_features=512, out_features=64, bias=True)
  )
  (norm): Identity()
  (fc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (head): Sequential(
    (0): Dropout(p=0.8, inplace=False)
    (1): LinearWithConstraint(in_features=32768, out_features=4, bias=True)
  )
)